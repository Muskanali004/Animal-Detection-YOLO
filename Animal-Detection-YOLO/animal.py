# -*- coding: utf-8 -*-
"""Animal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BQG8Vxpe5TheJSdA0fK3qYlnaInlWP6f
"""

!pip install ultralytics opencv-python matplotlib

from google.colab import files
uploaded = files.upload()

"""preprocessing"""

import cv2
import os
import numpy as np

def preprocess_image(image_path, save_path=None):
    # Load image
    image = cv2.imread('/content/animal.jpg')

    # Resize to fixed dimensions
    image = cv2.resize(image, (640, 640))

    # Convert to LAB and apply CLAHE for contrast enhancement
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    cl = clahe.apply(l)
    limg = cv2.merge((cl, a, b))
    enhanced = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)

    # Normalize pixel values to [0, 1]
    normalized = enhanced / 255.0

    # Convert back to uint8 for saving if needed
    output = (normalized * 255).astype(np.uint8)

    if save_path:
        cv2.imwrite(save_path, output)

    return output

from ultralytics import YOLO
import cv2
import matplotlib.pyplot as plt
import numpy as np

# Load model
model = YOLO("yolov8n.pt")

# Animal classes from COCO
animal_classes = [
    "bird", "cat", "dog", "horse", "sheep", "cow", "elephant",
    "bear", "zebra", "giraffe"
]

# Image path from uploaded file
image_path = list(uploaded.keys())[0]
image = cv2.imread(image_path)
rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Detect
results = model(rgb_image)

# Annotate animals
for result in results:
    boxes = result.boxes
    for box in boxes:
        class_id = int(box.cls[0])
        class_name = model.names[class_id]

        if class_name in animal_classes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            confidence = float(box.conf[0])
            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
            label = f"{class_name} {confidence:.2f}"
            cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX,
                        0.5, (0, 255, 0), 2)

# Display output
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
plt.figure(figsize=(10, 6))
plt.imshow(image_rgb)
plt.axis('off')
plt.title('Detected Animals')
plt.show()

from google.colab import files
uploaded = files.upload()

from ultralytics import YOLO
import cv2
import matplotlib.pyplot as plt
import numpy as np

# Load model
model = YOLO("yolov8n.pt")

# Animal classes from COCO
animal_classes = [
    "bird", "cat", "dog", "horse", "sheep", "cow", "elephant",
    "bear", "zebra", "giraffe"
]

# Image path from uploaded file
image_path = list(uploaded.keys())[0]
image = cv2.imread(image_path)
rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Detect
results = model(rgb_image)

# Annotate animals
for result in results:
    boxes = result.boxes
    for box in boxes:
        class_id = int(box.cls[0])
        class_name = model.names[class_id]

        if class_name in animal_classes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            confidence = float(box.conf[0])
            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
            label = f"{class_name} {confidence:.2f}"
            cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX,
                        0.5, (0, 255, 0), 2)

# Display output
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
plt.figure(figsize=(10, 6))
plt.imshow(image_rgb)
plt.axis('off')
plt.title('Detected Animals')
plt.show()

from google.colab import files
uploaded = files.upload()

from ultralytics import YOLO
import cv2
import matplotlib.pyplot as plt
import numpy as np

# Load model
model = YOLO("yolov8n.pt")

# Animal classes from COCO
animal_classes = [
    "bird", "cat", "dog", "horse", "sheep", "cow", "elephant",
    "bear", "zebra", "giraffe"
]

# Image path from uploaded file
image_path = list(uploaded.keys())[0]
image = cv2.imread(image_path)
rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Detect
results = model(rgb_image)

# Annotate animals
for result in results:
    boxes = result.boxes
    for box in boxes:
        class_id = int(box.cls[0])
        class_name = model.names[class_id]

        if class_name in animal_classes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            confidence = float(box.conf[0])
            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
            label = f"{class_name} {confidence:.2f}"
            cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX,
                        0.5, (0, 255, 0), 2)

# Display output
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
plt.figure(figsize=(10, 6))
plt.imshow(image_rgb)
plt.axis('off')
plt.title('Detected Animals')
plt.show()

from google.colab import files
uploaded = files.upload()

from ultralytics import YOLO
import cv2
import matplotlib.pyplot as plt
import numpy as np

# Load model
model = YOLO("yolov8n.pt")

# Animal classes from COCO
animal_classes = [
    "bird", "cat", "dog", "horse", "sheep", "cow", "elephant",
    "bear", "zebra", "giraffe"
]

# Image path from uploaded file
image_path = list(uploaded.keys())[0]
image = cv2.imread(image_path)
rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Detect
results = model(rgb_image)

# Annotate animals
for result in results:
    boxes = result.boxes
    for box in boxes:
        class_id = int(box.cls[0])
        class_name = model.names[class_id]

        if class_name in animal_classes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            confidence = float(box.conf[0])
            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
            label = f"{class_name} {confidence:.2f}"
            cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX,
                        0.5, (0, 255, 0), 2)

# Display output
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
plt.figure(figsize=(10, 6))
plt.imshow(image_rgb)
plt.axis('off')
plt.title('Detected Animals')
plt.show()

from google.colab import files
uploaded = files.upload()

import cv2
from ultralytics import YOLO
from google.colab.patches import cv2_imshow


# Load YOLOv8 model
model = YOLO("yolov8n.pt")  # You can use yolov8s.pt, yolov8m.pt, etc.

# Define COCO animal classes
animal_classes = [
    "bird", "cat", "dog", "horse", "sheep", "cow",
    "elephant", "bear", "zebra", "giraffe"
]

# Open video file
video_path = "/content/217300_small.mp4"  # Replace with your video
cap = cv2.VideoCapture(video_path)

# (Optional) Save output video
out = None
save_output = True

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # Run YOLOv8 on the frame
    results = model(frame)[0]

    # Draw detections
    for box in results.boxes:
        cls_id = int(box.cls[0])
        conf = float(box.conf[0])
        label = model.names[cls_id]

        if label in animal_classes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(frame, f"{label} {conf:.2f}", (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

    # Initialize writer if needed
    if save_output and out is None:
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        fps = cap.get(cv2.CAP_PROP_FPS)
        w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        out = cv2.VideoWriter('output_animals.mp4', fourcc, fps, (w, h))

    # Save or display frame
    if save_output:
        out.write(frame)

    cv2_imshow(frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
if out:
    out.release()
cv2.destroyAllWindows()

import cv2
from ultralytics import YOLO
from google.colab.patches import cv2_imshow


# Load YOLOv8 model
model = YOLO("yolov8n.pt")  # You can use yolov8s.pt, yolov8m.pt, etc.

# Define COCO animal classes
animal_classes = [
    "bird", "cat", "dog", "horse", "sheep", "cow",
    "elephant", "bear", "zebra", "giraffe"
]

# Open video file
video_path = "/content/cat.mp4"  # Replace with your video
cap = cv2.VideoCapture(video_path)

# (Optional) Save output video
out = None
save_output = True

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # Run YOLOv8 on the frame
    results = model(frame)[0]

    # Draw detections
    for box in results.boxes:
        cls_id = int(box.cls[0])
        conf = float(box.conf[0])
        label = model.names[cls_id]

        if label in animal_classes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(frame, f"{label} {conf:.2f}", (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

    # Initialize writer if needed
    if save_output and out is None:
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        fps = cap.get(cv2.CAP_PROP_FPS)
        w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        out = cv2.VideoWriter('output_animals.mp4', fourcc, fps, (w, h))

    # Save or display frame
    if save_output:
        out.write(frame)

    cv2_imshow(frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
if out:
    out.release()
cv2.destroyAllWindows()

